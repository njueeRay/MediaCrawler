"""
é£ä¹¦åŒæ­¥ç®¡ç†å™¨
å®Œå…¨åŸºäºé£ä¹¦å®˜æ–¹Python SDK (lark-oapi) å®ç°
å‚è€ƒå®˜æ–¹æ–‡æ¡£: https://open.feishu.cn/document/uAjLw4CM/ukTMukTMukTM/server-side-sdk/python--sdk/preparations-before-development
"""

import json
import os
import logging
import time
from typing import List, Dict, Optional
from pathlib import Path

logger = logging.getLogger(__name__)

try:
    import lark_oapi as lark
    from lark_oapi.api.bitable.v1 import (
        CreateAppTableRequest,
        CreateAppTableRequestBody,
        ReqTable,
        AppTableField,
        BatchCreateAppTableRecordRequest,
        BatchCreateAppTableRecordRequestBody,
        AppTableRecord,
        ListAppTableRecordRequest,
        CreateAppRequest,
        ReqApp
    )
    SDK_AVAILABLE = True
    logger.info("é£ä¹¦å®˜æ–¹SDKå¯¼å…¥æˆåŠŸ")
except ImportError as e:
    logger.error(f"lark-oapiæœªå®‰è£…æˆ–ç‰ˆæœ¬ä¸å…¼å®¹: {e}")
    logger.error("è¯·è¿è¡Œ: pip install lark-oapi")
    SDK_AVAILABLE = False

from .config import FeishuConfig
from .data_formatter import XHSDataFormatter

class FeishuSyncManager:
    """é£ä¹¦åŒæ­¥ç®¡ç†å™¨ - åŸºäºå®˜æ–¹SDK"""
    
    def __init__(self, app_id: str = None, app_secret: str = None, app_token: str = None, table_id: str = None):
        """
        åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨
        
        Args:
            app_id: é£ä¹¦åº”ç”¨IDï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
            app_secret: é£ä¹¦åº”ç”¨å¯†é’¥ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
            app_token: å¤šç»´è¡¨æ ¼Tokenï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
            table_id: æ•°æ®è¡¨IDï¼ˆå¯é€‰ï¼‰
        """
        if not SDK_AVAILABLE:
            raise ImportError("lark-oapiæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install lark-oapi")
        
        # ä½¿ç”¨ä¼ å…¥å‚æ•°æˆ–é…ç½®ç±»çš„é»˜è®¤å€¼
        self.app_id = app_id if app_id is not None else FeishuConfig.APP_ID
        self.app_secret = app_secret if app_secret is not None else FeishuConfig.APP_SECRET
        self.app_token = app_token if app_token is not None else FeishuConfig.APP_TOKEN
        self.table_id = table_id if table_id is not None else FeishuConfig.TABLE_ID
        
        # åˆ›å»ºå®˜æ–¹SDKå®¢æˆ·ç«¯
        self.client = self._create_lark_client()
        self.formatter = XHSDataFormatter()
        
    def _create_lark_client(self):
        """åˆ›å»ºé£ä¹¦å®˜æ–¹SDKå®¢æˆ·ç«¯"""
        try:
            client = lark.Client.builder() \
                .app_id(self.app_id) \
                .app_secret(self.app_secret) \
                .log_level(getattr(lark.LogLevel, FeishuConfig.LOG_LEVEL, lark.LogLevel.INFO)) \
                .build()
            
            logger.info("é£ä¹¦å®˜æ–¹SDKå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
            return client
        except Exception as e:
            logger.error(f"åˆ›å»ºé£ä¹¦å®¢æˆ·ç«¯å¤±è´¥: {e}")
            raise
    
    def _get_request_option(self):
        """è·å–è¯·æ±‚é€‰é¡¹"""
        return lark.RequestOption.builder().build()
    
    def setup_table(self, table_name: str = "å°çº¢ä¹¦æ•°æ®åˆ†æ") -> str:
        """
        åˆ›å»ºæ•°æ®è¡¨ - ä½¿ç”¨å®˜æ–¹SDKï¼Œå¤±è´¥æ—¶å›é€€åˆ°ç®€åŒ–ç‰ˆæœ¬
        
        Args:
            table_name: è¡¨æ ¼åç§°
            
        Returns:
            è¡¨æ ¼ID
        """
        if self.table_id:
            logger.info(f"ä½¿ç”¨å·²é…ç½®çš„è¡¨æ ¼ID: {self.table_id}")
            return self.table_id
        
        try:
            # å¦‚æœSDKä¸å¯ç”¨æˆ–æœ‰é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
            if not SDK_AVAILABLE:
                logger.info("SDKä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬åˆ›å»ºè¡¨æ ¼")
                self.table_id = self.create_table_simple(table_name)
                return self.table_id
            
            logger.info("å¼€å§‹åˆ›å»ºæ•°æ®è¡¨...")
            
            # å°è¯•ä½¿ç”¨SDKï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ°ç®€åŒ–ç‰ˆæœ¬
            try:
                # è·å–è¡¨æ ¼å­—æ®µå®šä¹‰
                fields_config = self.formatter.get_table_fields()
                
                # æ„å»ºå­—æ®µè¯·æ±‚å¯¹è±¡
                fields = []
                for field_config in fields_config:
                    field_builder = ReqField.builder() \
                        .field_name(field_config["field_name"]) \
                        .type(field_config["type"])
                    
                    # å¦‚æœæœ‰å±æ€§é…ç½®ï¼ˆå¦‚å•é€‰ã€å¤šé€‰çš„é€‰é¡¹ï¼‰
                    if "property" in field_config:
                        field_builder.property(field_config["property"])
                    
                    fields.append(field_builder.build())
                
                # æ„é€ åˆ›å»ºè¡¨æ ¼è¯·æ±‚
                request = CreateTableRequest.builder() \
                    .app_token(self.app_token) \
                    .request_body(ReqTable.builder()
                        .name(table_name)
                        .default_view_name("é»˜è®¤è§†å›¾")
                        .fields(fields)
                        .build()) \
                    .build()
                
                # å‘èµ·è¯·æ±‚
                response = self.client.bitable.v1.table.create(request, self._get_request_option())
                
                # å¤„ç†å“åº”
                if response.success():
                    self.table_id = response.data.table_id
                    logger.info(f"æ•°æ®è¡¨åˆ›å»ºæˆåŠŸï¼Œtable_id: {self.table_id}")
                    return self.table_id
                else:
                    raise Exception(f"SDKåˆ›å»ºè¡¨æ ¼å¤±è´¥ - Code: {response.code}, Msg: {response.msg}")
                    
            except Exception as sdk_error:
                logger.warning(f"SDKåˆ›å»ºè¡¨æ ¼å¤±è´¥ï¼Œå›é€€åˆ°ç®€åŒ–ç‰ˆæœ¬: {sdk_error}")
                self.table_id = self.create_table_simple(table_name)
                return self.table_id
                
        except Exception as e:
            logger.error(f"è®¾ç½®è¡¨æ ¼å¤±è´¥: {e}")
            raise
    
    def sync_from_json(self, json_file_path: str) -> Dict:
        """ä»JSONæ–‡ä»¶åŒæ­¥æ•°æ®"""
        logger.info(f"å¼€å§‹ä»JSONæ–‡ä»¶åŒæ­¥æ•°æ®: {json_file_path}")
        
        # å¦‚æœSDKä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
        if not SDK_AVAILABLE:
            logger.info("SDKä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬åŒæ­¥")
            return self.sync_from_json_simple(json_file_path)
        
        # åŠ è½½æ•°æ®
        raw_data = self.formatter.load_from_json(json_file_path)
        if not raw_data:
            return {"success": 0, "failed": 0, "error": "æ— æ³•åŠ è½½JSONæ•°æ®"}
        
        return self.sync_data(raw_data)
    
    def sync_from_csv(self, csv_file_path: str) -> Dict:
        """ä»CSVæ–‡ä»¶åŒæ­¥æ•°æ®"""
        logger.info(f"å¼€å§‹ä»CSVæ–‡ä»¶åŒæ­¥æ•°æ®: {csv_file_path}")
        
        # åŠ è½½æ•°æ®
        raw_data = self.formatter.load_from_csv(csv_file_path)
        if not raw_data:
            return {"success": 0, "failed": 0, "error": "æ— æ³•åŠ è½½CSVæ•°æ®"}
        
        return self.sync_data(raw_data)
    
    def sync_data(self, raw_data: List[Dict]) -> Dict:
        """
        åŒæ­¥æ•°æ®åˆ°é£ä¹¦ - ä½¿ç”¨å®˜æ–¹SDKï¼Œå¤±è´¥æ—¶å›é€€åˆ°ç®€åŒ–ç‰ˆæœ¬
        
        Args:
            raw_data: åŸå§‹æ•°æ®åˆ—è¡¨
            
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        if not raw_data:
            logger.warning("æ²¡æœ‰æ•°æ®éœ€è¦åŒæ­¥")
            return {"success": 0, "failed": 0}
        
        # å¦‚æœSDKä¸å¯ç”¨ï¼Œç›´æ¥ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
        if not SDK_AVAILABLE:
            logger.info("SDKä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬åŒæ­¥æ•°æ®")
            return self.sync_data_simple(raw_data)
        
        # ç¡®ä¿è¡¨æ ¼å·²åˆ›å»º
        if not self.table_id:
            self.setup_table()
        
        # æ ¼å¼åŒ–æ•°æ®
        logger.info(f"å¼€å§‹æ ¼å¼åŒ– {len(raw_data)} æ¡æ•°æ®...")
        formatted_records = self.formatter.format_batch_records(raw_data)
        
        if not formatted_records:
            logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„æ ¼å¼åŒ–æ•°æ®")
            return {"success": 0, "failed": len(raw_data)}
        
        # å»é‡å¤„ç†
        unique_records = self._deduplicate_records(formatted_records)
        
        # å°è¯•ä½¿ç”¨SDKæ‰¹é‡ä¸Šä¼ ï¼Œå¤±è´¥æ—¶å›é€€åˆ°ç®€åŒ–ç‰ˆæœ¬
        try:
            result = self._batch_create_records_with_sdk(unique_records)
            
            success_count = result.get("success", 0)
            failed_count = len(raw_data) - success_count
            
            logger.info(f"åŒæ­¥å®Œæˆ: æˆåŠŸ {success_count} æ¡, å¤±è´¥ {failed_count} æ¡")
            
            return {
                "success": success_count,
                "failed": failed_count,
                "total": len(raw_data),
                "table_id": self.table_id,
                "app_token": self.app_token
            }
            
        except Exception as sdk_error:
            logger.warning(f"SDKåŒæ­¥å¤±è´¥ï¼Œå›é€€åˆ°ç®€åŒ–ç‰ˆæœ¬: {sdk_error}")
            # ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬çš„æ‰¹é‡ä¸Šä¼ 
            result = self.batch_create_records_simple(unique_records, self.table_id)
            
            success_count = result.get("success", 0)
            failed_count = len(raw_data) - success_count
            
            logger.info(f"ç®€åŒ–ç‰ˆæœ¬åŒæ­¥å®Œæˆ: æˆåŠŸ {success_count} æ¡, å¤±è´¥ {failed_count} æ¡")
            logger.info(f"ğŸ”— è¡¨æ ¼é“¾æ¥: https://feishu.cn/base/{self.app_token}?table={self.table_id}")
            
            return {
                "success": success_count,
                "failed": failed_count,
                "total": len(raw_data),
                "table_id": self.table_id,
                "app_token": self.app_token
            }
    
    def _batch_create_records_with_sdk(self, records: List[Dict]) -> Dict:
        """
        ä½¿ç”¨å®˜æ–¹SDKæ‰¹é‡åˆ›å»ºè®°å½•
        
        Args:
            records: æ ¼å¼åŒ–åçš„è®°å½•åˆ—è¡¨
            
        Returns:
            åˆ›å»ºç»“æœ
        """
        success_count = 0
        batch_size = min(FeishuConfig.BATCH_SIZE, 500)  # é£ä¹¦APIé™åˆ¶
        
        logger.info(f"å¼€å§‹æ‰¹é‡ä¸Šä¼ ï¼Œæ€»è®¡ {len(records)} æ¡è®°å½•ï¼Œæ‰¹é‡å¤§å°: {batch_size}")
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(records), batch_size):
            batch_records = records[i:i + batch_size]
            batch_num = i // batch_size + 1
            
            try:
                logger.info(f"æ­£åœ¨å¤„ç†ç¬¬ {batch_num} æ‰¹ï¼Œå…± {len(batch_records)} æ¡è®°å½•...")
                
                # æ„å»ºè®°å½•å¯¹è±¡
                req_records = []
                for record in batch_records:
                    req_record = ReqRecord.builder().fields(record["fields"]).build()
                    req_records.append(req_record)
                
                # æ„é€ æ‰¹é‡åˆ›å»ºè¯·æ±‚
                request = BatchCreateTableRecordRequest.builder() \
                    .app_token(self.app_token) \
                    .table_id(self.table_id) \
                    .request_body(BatchCreateTableRecordReqBody.builder()
                        .records(req_records)
                        .build()) \
                    .build()
                
                # å‘èµ·è¯·æ±‚
                response = self.client.bitable.v1.table_record.batch_create(request, self._get_request_option())
                
                # å¤„ç†å“åº”
                if response.success():
                    batch_success = len(response.data.records) if response.data and response.data.records else len(batch_records)
                    success_count += batch_success
                    logger.info(f"ç¬¬ {batch_num} æ‰¹æˆåŠŸä¸Šä¼  {batch_success} æ¡è®°å½•")
                else:
                    error_msg = f"ç¬¬ {batch_num} æ‰¹ä¸Šä¼ å¤±è´¥ - Code: {response.code}, Msg: {response.msg}"
                    logger.error(error_msg)
                    # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
                    if hasattr(response, 'raw') and response.raw:
                        try:
                            error_detail = json.loads(response.raw.content)
                            logger.error(f"è¯¦ç»†é”™è¯¯: {json.dumps(error_detail, indent=2, ensure_ascii=False)}")
                        except:
                            pass
                
                # é¿å…APIé™æµ
                if i + batch_size < len(records):
                    time.sleep(FeishuConfig.RATE_LIMIT_DELAY)
                    
            except Exception as e:
                logger.error(f"ç¬¬ {batch_num} æ‰¹å¤„ç†å¤±è´¥: {e}")
                # ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹
        
        return {"success": success_count}
    
    def _deduplicate_records(self, records: List[Dict]) -> List[Dict]:
        """å»é‡å¤„ç†ï¼ˆåŸºäºç¬”è®°IDï¼‰"""
        seen_ids = set()
        unique_records = []
        
        for record in records:
            note_id = record["fields"].get("ç¬”è®°ID")
            if note_id and note_id not in seen_ids:
                seen_ids.add(note_id)
                unique_records.append(record)
        
        duplicate_count = len(records) - len(unique_records)
        if duplicate_count > 0:
            logger.info(f"å»é‡å¤„ç†: ç§»é™¤ {duplicate_count} æ¡é‡å¤è®°å½•")
        
        return unique_records
    
    def get_sync_status(self) -> Dict:
        """è·å–åŒæ­¥çŠ¶æ€"""
        try:
            if not self.table_id:
                return {"error": "è¡¨æ ¼IDæœªè®¾ç½®", "status": "error"}
            
            # è·å–è¡¨æ ¼è®°å½•åˆ—è¡¨ - ä½¿ç”¨å®˜æ–¹SDK
            request = ListTableRecordRequest.builder() \
                .app_token(self.app_token) \
                .table_id(self.table_id) \
                .page_size(1) \
                .build()
            
            response = self.client.bitable.v1.table_record.list(request, self._get_request_option())
            
            if response.success():
                total_records = response.data.total if response.data else 0
                return {
                    "total_records": total_records,
                    "table_id": self.table_id,
                    "app_token": self.app_token,
                    "status": "success"
                }
            else:
                error_msg = f"è·å–çŠ¶æ€å¤±è´¥ - Code: {response.code}, Msg: {response.msg}"
                return {"error": error_msg, "status": "error"}
                
        except Exception as e:
            logger.error(f"è·å–åŒæ­¥çŠ¶æ€å¤±è´¥: {e}")
            return {"error": str(e), "status": "error"}
    
    def sync_directory(self, dir_path: str, pattern: str = "*.json") -> Dict:
        """åŒæ­¥ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶"""
        if not os.path.exists(dir_path):
            error_msg = f"ç›®å½•ä¸å­˜åœ¨: {dir_path}"
            logger.error(error_msg)
            return {"error": error_msg}
        
        # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
        path_obj = Path(dir_path)
        files = list(path_obj.glob(pattern))
        
        if not files:
            logger.warning(f"ç›®å½• {dir_path} ä¸­æ²¡æœ‰æ‰¾åˆ°åŒ¹é… {pattern} çš„æ–‡ä»¶")
            return {"error": "æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶"}
        
        total_success = 0
        total_failed = 0
        processed_files = []
        
        for file_path in files:
            logger.info(f"æ­£åœ¨åŒæ­¥æ–‡ä»¶: {file_path}")
            
            try:
                # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©åŒæ­¥æ–¹æ³•
                if file_path.suffix.lower() == '.json':
                    result = self.sync_from_json(str(file_path))
                elif file_path.suffix.lower() == '.csv':
                    result = self.sync_from_csv(str(file_path))
                else:
                    logger.warning(f"è·³è¿‡ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path}")
                    continue
                
                if "error" not in result:
                    total_success += result.get("success", 0)
                    total_failed += result.get("failed", 0)
                    processed_files.append(str(file_path))
                else:
                    logger.error(f"åŒæ­¥æ–‡ä»¶ {file_path} å¤±è´¥: {result['error']}")
                    total_failed += 1
                    
            except Exception as e:
                logger.error(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                total_failed += 1
        
        return {
            "total_success": total_success,
            "total_failed": total_failed,
            "files_processed": len(processed_files),
            "processed_files": processed_files
        }
    
    # === ç®€åŒ–å®ç°æ–¹æ³•ï¼ˆåŸºäºrequestsï¼‰ ===
    
    def get_access_token_simple(self) -> str:
        """è·å–è®¿é—®ä»¤ç‰Œ - ç®€åŒ–ç‰ˆæœ¬"""
        import requests
        
        url = f"https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
        payload = {
            "app_id": self.app_id,
            "app_secret": self.app_secret
        }
        
        response = requests.post(url, json=payload)
        data = response.json()
        
        if data.get("code") == 0:
            return data["tenant_access_token"]
        else:
            raise Exception(f"è·å–è®¿é—®ä»¤ç‰Œå¤±è´¥: {data}")
    
    def create_table_simple(self, table_name: str = None) -> str:
        """åˆ›å»ºæ•°æ®è¡¨ - ç®€åŒ–ç‰ˆæœ¬"""
        import requests
        import time
        
        if table_name is None:
            table_name = f"å°çº¢ä¹¦æ•°æ®_{int(time.time())}"
        else:
            # ä¸ºäº†é¿å…é‡å¤ï¼Œåœ¨è¡¨ååæ·»åŠ æ—¶é—´æˆ³
            table_name = f"{table_name}_{int(time.time())}"
            
        access_token = self.get_access_token_simple()
        
        url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{self.app_token}/tables"
        headers = {
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        }
        
        # ç®€åŒ–çš„å­—æ®µå®šä¹‰
        fields = [
            {"field_name": "ç¬”è®°ID", "type": 1},
            {"field_name": "æ ‡é¢˜", "type": 1},
            {"field_name": "å†…å®¹æ‘˜è¦", "type": 1},
            {"field_name": "å‘å¸ƒæ—¶é—´", "type": 5},
            {"field_name": "ç”¨æˆ·æ˜µç§°", "type": 1},
            {"field_name": "ç‚¹èµæ•°", "type": 2},
            {"field_name": "æ”¶è—æ•°", "type": 2},
            {"field_name": "è¯„è®ºæ•°", "type": 2},
            {"field_name": "çƒ­åº¦è¯„åˆ†", "type": 2},
        ]
        
        payload = {
            "table": {
                "name": table_name,
                "default_view_name": "é»˜è®¤è§†å›¾",
                "fields": fields
            }
        }
        
        response = requests.post(url, headers=headers, json=payload)
        data = response.json()
        
        if data.get("code") == 0:
            return data["data"]["table_id"]
        else:
            raise Exception(f"åˆ›å»ºè¡¨æ ¼å¤±è´¥: {data}")
    
    def batch_create_records_simple(self, records: List[Dict], table_id: str) -> Dict:
        """æ‰¹é‡åˆ›å»ºè®°å½• - ç®€åŒ–ç‰ˆæœ¬"""
        import requests
        import time
        
        access_token = self.get_access_token_simple()
        
        url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{self.app_token}/tables/{table_id}/records/batch_create"
        headers = {
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        }
        
        success_count = 0
        batch_size = min(FeishuConfig.BATCH_SIZE, 50)  # å‡å°æ‰¹é‡å¤§å°ä»¥ç¡®ä¿ç¨³å®šæ€§
        
        for i in range(0, len(records), batch_size):
            batch_records = records[i:i + batch_size]
            payload = {"records": batch_records}
            
            try:
                response = requests.post(url, headers=headers, json=payload)
                data = response.json()
                
                if data.get("code") == 0:
                    batch_success = len(data.get("data", {}).get("records", []))
                    success_count += batch_success
                    logger.info(f"æ‰¹æ¬¡ä¸Šä¼ æˆåŠŸ: {batch_success} æ¡è®°å½•")
                else:
                    logger.error(f"æ‰¹æ¬¡ä¸Šä¼ å¤±è´¥: {data}")
                
                # é¿å…APIé™æµ
                if i + batch_size < len(records):
                    time.sleep(0.5)
                    
            except Exception as e:
                logger.error(f"æ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
        
        return {"success": success_count}
    
    def sync_data_simple(self, raw_data: List[Dict], table_name: str = None) -> Dict:
        """åŒæ­¥æ•°æ® - ç®€åŒ–ç‰ˆæœ¬"""
        try:
            # æ ¼å¼åŒ–æ•°æ®
            formatted_records = []
            for raw_record in raw_data:
                try:
                    record = {
                        "fields": {
                            "ç¬”è®°ID": raw_record.get('note_id', ''),
                            "æ ‡é¢˜": raw_record.get('title', '')[:50],
                            "å†…å®¹æ‘˜è¦": raw_record.get('desc', '')[:200],
                            "å‘å¸ƒæ—¶é—´": int(raw_record.get('time', 0)),
                            "ç”¨æˆ·æ˜µç§°": raw_record.get('nickname', ''),
                            "ç‚¹èµæ•°": int(raw_record.get('liked_count', 0)),
                            "æ”¶è—æ•°": int(raw_record.get('collected_count', 0)),
                            "è¯„è®ºæ•°": int(raw_record.get('comment_count', 0)),
                            "çƒ­åº¦è¯„åˆ†": self.formatter.calculate_heat_score(raw_record)
                        }
                    }
                    formatted_records.append(record)
                except Exception as e:
                    logger.error(f"æ ¼å¼åŒ–è®°å½•å¤±è´¥: {e}")
            
            # åˆ›å»ºè¡¨æ ¼
            table_id = self.create_table_simple(table_name)
            logger.info(f"æ•°æ®è¡¨åˆ›å»ºæˆåŠŸï¼Œtable_id: {table_id}")
            
            # ä¸Šä¼ æ•°æ®
            result = self.batch_create_records_simple(formatted_records, table_id)
            
            success_count = result.get("success", 0)
            failed_count = len(raw_data) - success_count
            
            logger.info(f"åŒæ­¥å®Œæˆ: æˆåŠŸ {success_count} æ¡, å¤±è´¥ {failed_count} æ¡")
            logger.info(f"ğŸ”— è¡¨æ ¼é“¾æ¥: https://feishu.cn/base/{self.app_token}?table={table_id}")
            
            return {
                "success": success_count,
                "failed": failed_count,
                "total": len(raw_data),
                "table_id": table_id,
                "app_token": self.app_token
            }
            
        except Exception as e:
            logger.error(f"åŒæ­¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return {"success": 0, "failed": len(raw_data), "error": str(e)}
    
    def sync_from_json_simple(self, json_file_path: str, table_name: str = None) -> Dict:
        """ä»JSONæ–‡ä»¶åŒæ­¥æ•°æ® - ç®€åŒ–ç‰ˆæœ¬"""
        logger.info(f"å¼€å§‹ä»JSONæ–‡ä»¶åŒæ­¥æ•°æ®: {json_file_path}")
        
        raw_data = self.formatter.load_from_json(json_file_path)
        if not raw_data:
            return {"success": 0, "failed": 0, "error": "æ— æ³•åŠ è½½JSONæ•°æ®"}
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè¡¨åï¼Œä»æ–‡ä»¶åç”Ÿæˆ
        if table_name is None:
            import os
            file_name = os.path.basename(json_file_path).replace('.json', '')
            table_name = f"å°çº¢ä¹¦_{file_name}"
        
        return self.sync_data_simple(raw_data, table_name)
